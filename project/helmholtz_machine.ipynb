{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.nnet import conv2d, conv2d_transpose\n",
    "from theano.tensor.signal import pool\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "theano.config.optimizer='fast_compile'\n",
    "theano.config.exception_verbosity='high'\n",
    "theano.config.compute_test_value = 'off'\n",
    "theano.config.floatX = 'float32'\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create shared variables for using gpu\n",
    "def shared_dataset(data, borrow=True, data_types=['float32','int32']):\n",
    "    if type(data) is not list:\n",
    "        data = list(data)\n",
    "    output = []\n",
    "    for i, x in enumerate(data):\n",
    "        output.append(theano.shared(np.asarray(x, dtype=data_types[i]), borrow=borrow))\n",
    "    return output\n",
    "\n",
    "def load_dataset(dataset):\n",
    "    # get path/file for dataset\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the current directory.\n",
    "        new_path = os.path.join(os.curdir, dataset)\n",
    "        if os.path.isfile(new_path) or data_file == 'mnist.pkl.gz':\n",
    "            dataset = new_path\n",
    "    # download from website\n",
    "    if (not os.path.isfile(dataset)) and data_file == 'mnist.pkl.gz':\n",
    "        from six.moves import urllib\n",
    "        origin = ('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz')\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urllib.request.urlretrieve(origin, dataset)\n",
    "    # load from pickle\n",
    "    print('... loading data')\n",
    "    with gzip.open(dataset, 'rb') as f:\n",
    "        try:\n",
    "            train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "        except:\n",
    "            train_set, valid_set, test_set = pickle.load(f)\n",
    "    # set test/valid/train sets\n",
    "    test_set_x, test_set_y = shared_dataset(test_set)\n",
    "    valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "    train_set_x, train_set_y = shared_dataset(train_set)\n",
    "    # combine datasets\n",
    "    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y), (test_set_x, test_set_y)]\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HelmholtzLayer(object):\n",
    "    '''WRITEME'''\n",
    "    def __init__(self, input, n_in, n_out, th_rng=None, top_layer=False):\n",
    "        # init vars\n",
    "        self.input = input\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        # init th_rng if None\n",
    "        if th_rng is None:\n",
    "            self.th_rng = RandomStreams(1)\n",
    "        else:\n",
    "            self.th_rng = th_rng\n",
    "        self.top_layer = top_layer\n",
    "        \n",
    "        # recognition weights\n",
    "        self.WR = theano.shared(np.zeros((n_in,n_out), dtype=theano.config.floatX),\n",
    "                                borrow=True, name='WR')\n",
    "        # recognition biases\n",
    "        self.bR = theano.shared(np.zeros((n_out,), dtype=theano.config.floatX), \n",
    "                                borrow=True, name='bR')\n",
    "        # generative weights\n",
    "        self.WG = theano.shared(np.zeros((n_out,n_in), dtype=theano.config.floatX),\n",
    "                                borrow=True, name='WG')\n",
    "        # generative biases\n",
    "        self.bG = theano.shared(np.zeros((n_in,), dtype=theano.config.floatX),\n",
    "                                borrow=True, name='bG')\n",
    "        \n",
    "        # if top_layer, remove shared WR, bR, WG\n",
    "        if self.top_layer:\n",
    "            self.WR = T.zeros_like(self.WR)\n",
    "            self.bR = T.zeros_like(self.bR)\n",
    "            self.WG = T.zeros_like(self.WG)\n",
    "            # set gen_params, rec_params\n",
    "            self.gen_params = [self.bG]\n",
    "            self.rec_params = []\n",
    "        else:\n",
    "            # set gen_params, rec_params\n",
    "            self.gen_params = [self.WG, self.bG]\n",
    "            self.rec_params = [self.WR, self.bR]\n",
    "        \n",
    "        # set output\n",
    "        self.output = self.sample_h_given_v(self.input)\n",
    "        \n",
    "        # init reconstr, top_down, p to None\n",
    "        self.reconstr = None\n",
    "        self.top_down = None\n",
    "        \n",
    "    def propup(self, v):\n",
    "        return T.nnet.sigmoid(T.dot(v, self.WR) + self.bR)\n",
    "    \n",
    "    def propdown(self, h):\n",
    "        return T.nnet.sigmoid(T.dot(h, self.WG) + self.bG)\n",
    "    \n",
    "    def sample_h_given_v(self, v):\n",
    "        h = self.propup(v)\n",
    "        return self.th_rng.binomial(size=h.shape, n=1, p=h, dtype=theano.config.floatX)\n",
    "    \n",
    "    def sample_v_given_h(self, h):\n",
    "        v = self.propdown(h)\n",
    "        return self.th_rng.binomial(size=v.shape, n=1, p=v, dtype=theano.config.floatX)\n",
    "    \n",
    "    def get_wake_derivs(self):\n",
    "        '''WRITEME'''\n",
    "        # get delta by propagating down with output\n",
    "        delta = self.propdown(self.output)\n",
    "        \n",
    "        # get wake derivatives\n",
    "        dWG = T.dot(self.output.T, (self.input - delta))\n",
    "        dbG = T.mean((self.input - delta), axis=0)\n",
    "        \n",
    "        # if top_layer, no WG derivs\n",
    "        if self.top_layer:\n",
    "            return [dbG]\n",
    "        else:\n",
    "            return dWG, dbG\n",
    "    \n",
    "    def get_sleep_derivs(self):\n",
    "        '''WRITEME'''\n",
    "        # if top_layer, no sleep derivs\n",
    "        if self.top_layer:\n",
    "            return []\n",
    "        \n",
    "        # get psi by propagating up with reconstr\n",
    "        psi = self.propup(self.reconstr)\n",
    "        \n",
    "        # get sleep derivatives\n",
    "        dWR = T.dot(self.reconstr.T, (self.top_down - psi))\n",
    "        dbR = T.mean((self.top_down - psi), axis=0)\n",
    "        return dWR, dbR\n",
    "        \n",
    "    def set_reconstr(self, top_down):\n",
    "        self.top_down = top_down\n",
    "        self.reconstr = self.sample_v_given_h(self.top_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HelmholtzMachine(object):\n",
    "    '''WRITEME'''\n",
    "    def __init__(self, n_layers, n_ins, th_rng=None):\n",
    "        # init vars\n",
    "        self.n_layers = n_layers\n",
    "        self.n_ins = n_ins\n",
    "        if th_rng is None:\n",
    "            self.th_rng = RandomStreams(np.random.randint(2**30))\n",
    "        else:\n",
    "            self.th_rng = th_rng\n",
    "            \n",
    "        # init first layer input variable\n",
    "        self.v = T.matrix('v')\n",
    "        \n",
    "        # for each layer, append HelmholtzLayer\n",
    "        self.helmholtz_layers = []\n",
    "        for n in range(self.n_layers):\n",
    "            # set bG_1 to True if top layer, False otherwise\n",
    "            is_top_layer = (n == self.n_layers - 1)\n",
    "            # set input_layer\n",
    "            if n == 0:\n",
    "                input_layer = self.v\n",
    "            else:\n",
    "                input_layer = self.helmholtz_layers[-1].output\n",
    "            # set n_out\n",
    "            if is_top_layer:\n",
    "                n_out = 1\n",
    "            else:\n",
    "                n_out = self.n_ins[n+1]\n",
    "            # create helmholtz layer\n",
    "            self.helmholtz_layers.append(HelmholtzLayer(input_layer, \n",
    "                                                         self.n_ins[n], \n",
    "                                                         n_out,\n",
    "                                                         th_rng=self.th_rng,\n",
    "                                                         top_layer=is_top_layer))\n",
    "            \n",
    "        # for each layer, set reconstr\n",
    "        for n in range(self.n_layers-1, -1, -1):\n",
    "            # for top layer, top_down is zeros\n",
    "            if n == self.n_layers-1:\n",
    "                top_down = T.zeros((1,1), dtype=theano.config.floatX)\n",
    "            else:\n",
    "                top_down = self.helmholtz_layers[n+1].reconstr\n",
    "            # set top_down and reconstr\n",
    "            self.helmholtz_layers[n].set_reconstr(top_down)\n",
    "    \n",
    "    def model_sample(self):\n",
    "        return self.helmholtz_layers[0].reconstr[0]\n",
    "    \n",
    "    def KL_part(self, d, D, M):\n",
    "        d0 = 1. - d\n",
    "        D0 = 1. - D\n",
    "        M0 = 1. - M\n",
    "        p_d = T.mean(T.eq(T.dot(d, D.T), T.dot(d, d.T)) * T.eq(T.dot(d0, D0.T), T.dot(d0, d0.T)))\n",
    "        p_m = T.mean(T.eq(T.dot(d, M.T), T.dot(d, d.T)) * T.eq(T.dot(d0, M0.T), T.dot(d0, d0.T)))\n",
    "        return T.mul(p_d, T.sub(T.log(p_d), T.log(p_m + 1e-6)))\n",
    "    \n",
    "    def KL(self):\n",
    "        D = T.matrix('D')\n",
    "        # get model samples\n",
    "        M,_ = theano.scan(self.model_sample, n_steps=D.shape[0])\n",
    "        # get unique probabilities of each data vector\n",
    "        KLs, _ = theano.scan(self.KL_part, sequences=[D], non_sequences=[D, M])\n",
    "        KLs = T.extra_ops.Unique(True)(KLs)[0]\n",
    "        return theano.function([D], T.sum(KLs))\n",
    "    \n",
    "    def MSE(self):\n",
    "        D = T.matrix('D')\n",
    "        M,_ = theano.scan(self.model_sample, n_steps=D.shape[0])\n",
    "        return theano.function([D], T.mean(T.square(D - M)))\n",
    "    \n",
    "    def free_energy_part(self, n):\n",
    "        q = self.helmholtz_layers[n].propup(self.helmholtz_layers[n].input)\n",
    "        p = self.helmholtz_layers[n+1].propdown(self.helmholtz_layers[n+1].output)\n",
    "        return T.sum(T.add(T.mul(q, T.log(q + 1e-6) - T.log(p + 1e-6)),\n",
    "                           T.mul((1. - q), T.log(1. - q + 1e-6) - T.log(1. - p + 1e-6))))\n",
    "    \n",
    "    def free_energy(self):\n",
    "        FEs = []\n",
    "        # for layer 0, q is data, p are reconstructions\n",
    "        q = T.matrix('q')\n",
    "        p = self.helmholtz_layers[0].propdown(self.helmholtz_layers[0].output)\n",
    "        # compute FE part for layer 0\n",
    "        FEs.append(T.sum(T.add(T.mul(q, T.log(q + 1e-6) - T.log(p + 1e-6)),\n",
    "                               T.mul((1. - q), T.log(1. - q + 1e-6) - T.log(1. - p + 1e-6)))))\n",
    "        # compute for all other layers (except top layer)\n",
    "        for n in range(self.n_layers-1):\n",
    "            FEs.append(self.free_energy_part(n))\n",
    "        # return function that can compute FE for given data\n",
    "        return theano.function([q], T.sum(FEs), givens={self.v: q})\n",
    "    \n",
    "    def train_function(self, train_data, batch_size, cost_type='free_energy'):\n",
    "        # init vars\n",
    "        awake = T.iscalar('awake').astype(theano.config.floatX)\n",
    "        lr = [T.scalar('lr_' + str(n)) for n in range(self.n_layers)]\n",
    "        idx = T.iscalar('idx')\n",
    "        v = train_data[idx * batch_size:(idx + 1) * batch_size]  \n",
    "            \n",
    "        # parameter updates for theano function\n",
    "        updates = []\n",
    "        for n in range(self.n_layers):\n",
    "            # wake phase\n",
    "            wake_derivs = self.helmholtz_layers[n].get_wake_derivs()\n",
    "            for param, gparam in zip(self.helmholtz_layers[n].gen_params, wake_derivs):\n",
    "                updates.append((param, param + awake * lr[n] * gparam))\n",
    "            # sleep phase\n",
    "            sleep_derivs = self.helmholtz_layers[n].get_sleep_derivs()\n",
    "            for param, gparam in zip(self.helmholtz_layers[n].rec_params, sleep_derivs):\n",
    "                updates.append((param, param + (1. - awake) * lr[n] * gparam))\n",
    "        \n",
    "        # create train_fn\n",
    "        inputs = [idx, awake] + lr\n",
    "        train_fn = theano.function(inputs, [], updates=updates, givens={self.v: v})\n",
    "        \n",
    "        # set cost_fn\n",
    "        if cost_type == 'KL':\n",
    "            cost_fn = self.KL()\n",
    "        elif cost_type == 'MSE':\n",
    "            cost_fn = self.MSE()\n",
    "        elif cost_type == 'free_energy':\n",
    "            cost_fn = self.free_energy()\n",
    "        else:\n",
    "            cost_fn = None\n",
    "            \n",
    "        return train_fn, cost_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('mnist.pkl.gz')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create bar data\n",
    "data = np.zeros((1000, 3, 3), dtype=theano.config.floatX)\n",
    "for n in range(data.shape[0]):\n",
    "    # Horizontal bars 1/3, vertical bars 2/3\n",
    "    if np.random.rand() > (2./3.): \n",
    "        data[n, np.random.randint(data.shape[1]), :] = 1.\n",
    "    else:\n",
    "        data[n, :, np.random.randint(data.shape[2])] = 1.\n",
    "data = np.reshape(data, (data.shape[0], -1))\n",
    "data = T.as_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialize helmholtz machine\n",
    "# th_rng = RandomStreams(1)\n",
    "helm = HelmholtzMachine(3, [784, 512, 128]) #[9,6,1]) # \n",
    "# create training function\n",
    "batch_size = 1\n",
    "train_fn, cost_fn = helm.train_function(data, batch_size, cost_type='free_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Epoch 0 (30.00%): 1176216.5000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-562-c463b16afad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# for each batch_size within n_batches, train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# wake phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sleep phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/theissjd/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "lr = [0.001]*helm.n_layers\n",
    "n_batches = data.eval().shape[0]//batch_size\n",
    "monitor = data.eval().shape[0]//10\n",
    "cost_history = []\n",
    "im_size = (28,28)\n",
    "\n",
    "# train in epochs\n",
    "for epoch in range(50):\n",
    "    cost = []\n",
    "    # for each batch_size within n_batches, train\n",
    "    for n in range(n_batches):\n",
    "        train_fn(n, True, *lr) # wake phase\n",
    "        train_fn(n, False, *lr) # sleep phase\n",
    "        \n",
    "        # monitor samples\n",
    "        if n % monitor == 0:\n",
    "            # get cost\n",
    "            rand_idxs = np.random.permutation(data.eval().shape[0])\n",
    "            cost.append(cost_fn(data[rand_idxs[:monitor]].eval()))\n",
    "            # print progress\n",
    "            clear_output(wait=True)\n",
    "            display('Epoch %d (%0.2f%%): %0.4f' % (epoch, 100. * n/n_batches, np.mean(cost)))\n",
    "            # plot sample from model\n",
    "            plt.imshow(helm.model_sample().eval().reshape(im_size), cmap='gray')\n",
    "            plt.show()\n",
    "            # plot cost history\n",
    "            plt.plot(cost_history)\n",
    "            plt.show()\n",
    "    # append cost history\n",
    "    cost_history.append(np.mean(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwy81Zfilpgy/1NT/A9Cm9dicR/1zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(helm.model_sample().eval().reshape(im_size), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
